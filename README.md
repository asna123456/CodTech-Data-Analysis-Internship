 CodeTech Data Analysis Internship Deliverables

This repository contains the completed tasks for the CodeTech Data Analysis Internship.

---

## Task 1: Big Data Analysis (PySpark)

### Goal
To perform analysis on a large dataset (1 Million records) using PySpark to demonstrate scalability and distributed processing capabilities.

### Technologies Used
* PySpark (for distributed processing and transformation)
* Pandas & Matplotlib (for visualization of aggregated results)

### Key Insight
The analysis successfully calculated the total revenue across all 1 million transactions in milliseconds, identifying **[E.g., Electronics]** as the highest revenue-generating category. This demonstrates the efficiency of PySpark over traditional tools for large data volumes.

### File
* **Notebook Link:** [Task 1 - PySpark Analysis](https://github.com/asna123456/Codetech-Data-Analysis-Internship/blob/f05b24d909a2e702222d1701de33e72e5ac73176/Task1_BigDataAnalysis.ipynb)
